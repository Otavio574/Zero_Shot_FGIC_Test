"""
Avalia√ß√£o Zero-Shot de CLIP usando embeddings pr√©-calculados e templates.
Este script carrega embeddings de imagens j√° extra√≠dos, gera embeddings de texto
a partir dos templates CLIP, e avalia a acur√°cia zero-shot.
"""

import os
import json
import torch
import numpy as np
from tqdm import tqdm
from sklearn.metrics import accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
from transformers import AutoProcessor, AutoModel
from pathlib import Path
from glob import glob
from collections import Counter
import traceback

# ============================
# CONFIGURA√á√ïES
# ============================

def load_datasets_from_summary(summary_path: Path) -> dict:
    """Carrega configura√ß√£o de datasets do summary.json"""
    if not summary_path.exists():
        print(f"‚ö†Ô∏è ¬†Arquivo {summary_path} n√£o encontrado!")
        return {}
    
    with open(summary_path, 'r', encoding='utf-8') as f:
        summary = json.load(f)
    
    datasets = {}
    
    if isinstance(summary, list):
        for item in summary:
            dataset_name = item.get('dataset')
            dataset_path = item.get('path')
            if dataset_name and dataset_path:
                datasets[dataset_name] = dataset_path
    elif isinstance(summary, dict):
        # Tenta extrair a lista de datasets de um dicion√°rio, se for o caso
        if 'datasets' in summary:
            datasets = summary['datasets']
        else:
            # Assume que o dicion√°rio j√° √© o mapeamento nome:caminho
            datasets = summary
    
    return datasets

SUMMARY_PATH = Path("outputs/analysis/summary.json")
DATASETS = load_datasets_from_summary(SUMMARY_PATH)

MODEL_NAME = "openai/clip-vit-base-patch32"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
RESULTS_DIR = "all_zero-shot_results/results_zero_shot_baseline"

os.makedirs(RESULTS_DIR, exist_ok=True)

# ============================
# FUN√á√ïES AUXILIARES
# ============================

def load_templates(dataset_name):
    """Carrega template do dataset e sanitiza suas chaves para matching robusto."""
    path = os.path.join("descriptors", f"{dataset_name}_templates.json")
    if not os.path.exists(path):
        # Tenta o nome corrigido para o novo formato
        path = os.path.join("descriptors", f"{dataset_name}_descriptors.json") 
        if not os.path.exists(path):
            print(f"‚ö†Ô∏è ¬†Templates/Descriptors n√£o encontrados: {path}")
            return {}
    
    with open(path, "r", encoding="utf-8") as f:
        templates = json.load(f)
        
    # CRUCIAL: Saneia TODAS as chaves do dicion√°rio lido
    sanitized_templates = {normalize_class_key(key): value for key, value in templates.items()}
    return sanitized_templates


def normalize_class_key(key: str) -> str:
    """Normaliza uma string de classe eliminando case, espa√ßos e caracteres especiais comuns."""
    key = key.strip()
    key = key.lower()
    # Remove underscores, h√≠fens e pontos (crucial para '001.Black_footed_Albatross')
    key = key.replace('_', '').replace('-', '').replace('.', '') 
    key = key.replace(' ', '')
    return key


def extract_class_from_path(path, dataset_path):
    """Extrai nome da classe de um path de imagem"""
    path_obj = Path(path)
    dataset_obj = Path(dataset_path)
    
    try:
        # Pega o path relativo ao dataset
        rel_path = path_obj.relative_to(dataset_obj)
        # A classe geralmente √© a primeira pasta depois do dataset
        if len(rel_path.parts) >= 2:
            return rel_path.parts[0]
        else:
            # Fallback para o nome da pasta pai se a estrutura for plana
            return path_obj.parent.name 
    except ValueError:
        # Se n√£o conseguir fazer relative_to, usa o nome da pasta pai
        return path_obj.parent.name


def match_descriptor_to_class(class_name: str, template: dict) -> str:
    """
    Realiza o match do nome da classe (do path) com os template
    (com chaves normalizadas) usando a normaliza√ß√£o universal.
    """
    
    # CRUCIAL: Normaliza o nome da classe extra√≠do do path
    class_normalized = normalize_class_key(class_name) 
    
    # O match agora √© direto e garantido, pois ambos os lados foram normalizados
    if class_normalized in template:
        return template[class_normalized]

    # Fallback (Apenas se o descriptor realmente n√£o existir no JSON)
    print(f"‚ö†Ô∏è ¬†Fallback para classe n√£o mapeada: {class_name}")
    # Usa o nome leg√≠vel (com espa√ßos, sem o prefixo num√©rico) no template de fallback
    readable_name = class_name.replace('_', ' ').replace('-', ' ').replace('.', ' ')
    
    # ‚ö†Ô∏è Este √© o prompt FRACA de fallback
    return f"a photo of a {readable_name}"


def load_embeddings_and_generate_text(dataset_name, dataset_path, template, model, processor):
    """Carrega embeddings de imagem e gera embeddings de texto dos template"""
    
    # Carrega image embeddings
    embedding_path = os.path.join("embeddings", f"{dataset_name}.pt")
    
    if not os.path.exists(embedding_path):
        print(f"‚ö†Ô∏è ¬†Embeddings n√£o encontrados: {embedding_path}")
        return None, None, None, None
    
    print(f"üìÇ Carregando embeddings: {embedding_path}")
    embeddings_data = torch.load(embedding_path, map_location='cpu')
    
    # Detecta formato
    if isinstance(embeddings_data, dict):
        # Formato: {'image_embeddings': tensor, 'image_paths': list}
        image_embeds = embeddings_data.get('image_embeddings')
        image_paths = embeddings_data.get('image_paths', embeddings_data.get('paths'))
        print(f" ¬†Formato: dicion√°rio com paths")
    else:
        # Formato: apenas tensor
        image_embeds = embeddings_data
        image_paths = None
        print(f" ¬†Formato: tensor direto")
    
    if image_embeds is None:
        print(f"‚ùå N√£o foi poss√≠vel extrair embeddings do arquivo")
        return None, None, None, None
    
    # Normaliza embeddings se necess√°rio
    if image_embeds.norm(dim=-1, keepdim=True).mean() > 1.1:
        print(f" ¬†Normalizando image embeddings...")
        image_embeds = image_embeds / image_embeds.norm(dim=-1, keepdim=True)
    
    # üö® CORRE√á√ÉO CR√çTICA DO RESHAPE üö®
    # Garante que o tensor est√° no formato [N, 512], onde N √© o n√∫mero de imagens.
    if image_embeds.dim() == 1:
        # Se for 1D, calculamos N = tamanho total / 512 (dimens√£o do ViT-B/32)
        N = image_embeds.size(0) // 512 
        # S√≥ faz o reshape se o tamanho for divis√≠vel por 512
        if image_embeds.size(0) % 512 == 0 and N > 0:
            image_embeds = image_embeds.view(N, 512)
            print(f" ¬†‚ö†Ô∏è Embeddings 1D REDIMENSIONADOS para {image_embeds.shape}")
        else:
            # Caso contr√°rio, o tensor est√° incorreto
            print(f"‚ùå Erro de formato: Tamanho do tensor ({image_embeds.size(0)}) n√£o √© divis√≠vel por 512.")
            return None, None, None, None
            
    # Verifica a dimens√£o final
    if image_embeds.dim() != 2 or image_embeds.shape[1] != 512:
        print(f"‚ùå Erro de formato: Shape final esperado [N, 512], encontrado {image_embeds.shape}")
        return None, None, None, None

    print(f" ¬†Shape: {image_embeds.shape}")
    
    # Extrai classes e labels
    if image_paths:
        # Usa paths para extrair classes
        labels = []
        class_to_idx = {}
        class_names = []
        
        # C√ìDIGO CORRIGIDO: Alinhamento das labels com os paths
        for path in image_paths:
            class_name_raw = extract_class_from_path(path, dataset_path)

            # O nome da classe para MATCH DEVE SER A VERS√ÉO NORMALIZADA (p/ casar com a chave JSON)
            class_name_for_match = normalize_class_key(class_name_raw)

            if class_name_for_match not in class_to_idx:
                class_to_idx[class_name_for_match] = len(class_names)
                # Mant√©m o nome da classe RAW/n√£o normalizado para exibi√ß√£o
                class_names.append(class_name_raw) 

            # Labels usa o √≠ndice da classe normalizada
            labels.append(class_to_idx[class_name_for_match])

        labels = np.array(labels)
    else:
        # C√ìDIGO DE FALLBACK PARA INFER√äNCIA DE CLASSES
        print("‚ö†Ô∏è ¬†Sem paths salvos, inferindo estrutura...")
        class_folders = {}
        dataset_path_obj = Path(dataset_path)
        
        for img_path in dataset_path_obj.rglob("*"):
            if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:
                class_name = img_path.parent.name
                if class_name not in class_folders:
                    class_folders[class_name] = []
                class_folders[class_name].append(str(img_path))
        
        if not class_folders:
            print("‚ùå N√£o foi poss√≠vel inferir classes")
            return None, None, None, None
        
        class_names = sorted(class_folders.keys())
        print(f" ¬†Classes inferidas: {len(class_names)}")
        
        all_paths = []
        labels = []
        for class_idx, class_name in enumerate(class_names):
            paths = sorted(class_folders[class_name])
            all_paths.extend(paths)
            labels.extend([class_idx] * len(paths))
        
        labels = np.array(labels[:len(image_embeds)])
        print(f" ¬†‚ö†Ô∏è ¬†Labels inferidos (pode n√£o estar perfeitamente alinhado)")
    
    print(f" ¬†Total de imagens: {len(labels)}")
    print(f" ¬†Classes √∫nicas: {len(set(labels))}")
    print(f" ¬†Distribui√ß√£o de classes:")
    class_counts = Counter(labels)
    
    # Mapeia os √≠ndices de volta para os nomes de classe (usando a lista class_names)
    sorted_class_counts = sorted(class_counts.items(), key=lambda item: item[1], reverse=True)
    
    for cls_idx, count in sorted_class_counts[:5]:
        cls_name = class_names[cls_idx] if cls_idx < len(class_names) else f"Class_{cls_idx}"
        print(f" ¬† ¬† ¬†{cls_name}: {count} imagens")
    
    # Gera text embeddings dos templates
    class_texts = []
    
    # --- VERIFICA√á√ÉO DE COBERTURA (adicionado para debug) ---
    descriptor_coverage = 0
    fallback_count = 0
    
    fallback_prefix = "a photo of a "
    
    # IMPORTANTE: Aqui, class_names √© a lista de nomes de classe (RAW) na ordem do √≠ndice 0..N
    # Usamos o nome da classe (RAW) para fazer o match no template.
    for class_name_raw in class_names:
        description = match_descriptor_to_class(class_name_raw, template)
        
        # Simula o fallback fraco para contagem
        readable_name = class_name_raw.replace('_', ' ').replace('-', ' ').replace('.', ' ')
        fallback_description = f"{fallback_prefix}{readable_name}" 
        
        if description == fallback_description:
            fallback_count += 1
        else:
            descriptor_coverage += 1
            
        class_texts.append(description)
        
    print(f"\nüìù Gerando text embeddings para {len(class_texts)} classes...")
    # ESTA √â A MENSAGEM CR√çTICA
    print(f"üìä Cobertura de template: {descriptor_coverage} espec√≠ficos encontrados, {fallback_count} usando fallback gen√©rico.")
    
    # ... (restante do c√≥digo)
    

    
    print(f" ¬†Exemplos de textos:")
    for i in range(min(3, len(class_texts))):
        txt = class_texts[i]
        print(f" ¬† ¬† ¬†{class_names[i]}: {txt[:70]}...")
    
    text_inputs = processor(
        text=class_texts,
        padding=True,
        truncation=True,
        max_length=77,
        return_tensors="pt"
    ).to(DEVICE)
    
    with torch.no_grad():
        text_embeds = model.get_text_features(**text_inputs)
        text_embeds = text_embeds / text_embeds.norm(dim=-1, keepdim=True)
    
    print(f"‚úÖ Embeddings carregados e processados!")


    # === IN√çCIO DO BLOCO DE DIAGN√ìSTICO FINAL (INSERIR AQUI) ===
    print("\n--- DIAGN√ìSTICO DO MATCH ---")
    
    # Exemplo de Chave JSON (Nome da Classe no Dicion√°rio)
    if template:
        first_json_key_raw = list(template.keys())[0]
        print(f"1. Chave JSON Carregada (1¬™): '{first_json_key_raw}'")
        print(f" ¬† (Normalizada p/ busca): '{normalize_class_key(first_json_key_raw)}'")
    else:
        print("1. ERRO: Dicion√°rio de template est√° vazio.")
        
    # Exemplo de Nome de Classe do Path
    if class_names:
        first_class_name_raw = class_names[0]
        print(f"2. Nome da Classe do Path (1¬™): '{first_class_name_raw}'")
        print(f" ¬† (Normalizada p/ busca): '{normalize_class_key(first_class_name_raw)}'")
    
        # Teste de Igualdade Agressivo
        if template:
            sane_json = normalize_class_key(first_json_key_raw)
            sane_path = normalize_class_key(first_class_name_raw)
            
            is_equal = (sane_json == sane_path)
            print(f"3. Teste de Igualdade (Saneado): {is_equal}")
            if not is_equal:
                print(f" ¬† DIFEREN√áA: len(JSON)={len(sane_json)} vs len(PATH)={len(sane_path)}")
                
    print("--- FIM DO DIAGN√ìSTICO DO MATCH ---\n")
    # === FIM DO BLOCO DE DIAGN√ìSTICO FINAL ===
    
    return image_embeds, text_embeds.cpu(), labels, class_names


def evaluate_zero_shot(image_embeds, text_embeds, labels):
    """Calcula acur√°cia zero-shot."""
    print(f"\nüîç Calculando similaridades...")
    print(f" ¬†Image embeds: {image_embeds.shape}")
    print(f" ¬†Text embeds: {text_embeds.shape}")
    
    # Garante que ambos est√£o normalizados (embora j√° tenham sido no load)
    # Re-normaliza√ß√£o √© segura, mas tecnicamente desnecess√°ria se o load for perfeito
    image_embeds = image_embeds / image_embeds.norm(dim=-1, keepdim=True)
    text_embeds = text_embeds / text_embeds.norm(dim=-1, keepdim=True)
    
    # Similaridade de Cosseno (produto escalar de vetores normalizados)
    # Esta √© a linha que falhava devido ao shape incorreto do image_embeds
    sims = image_embeds @ text_embeds.T 
    preds = sims.argmax(dim=-1).numpy()
    acc = accuracy_score(labels, preds)
    
    print(f" ¬†Similaridade m√©dia: {sims.mean():.4f}")
    print(f" ¬†Similaridade m√°xima: {sims.max():.4f}")
    print(f" ¬†Predi√ß√µes √∫nicas: {len(np.unique(preds))}")
    
    return acc, preds


def plot_confusion_matrix(labels, preds, class_names, output_path):
    """Gera e salva matriz de confus√£o"""
    try:
        # Limita o n√∫mero de classes para visualiza√ß√£o para evitar gr√°ficos gigantes
        max_classes = 50
        
        # Filtra para as top N classes se houver muitas
        if len(class_names) > max_classes:
            print(f" ¬†‚ö†Ô∏è ¬†Muitas classes ({len(class_names)}), mostrando top {max_classes} mais frequentes")
            unique, counts = np.unique(labels, return_counts=True)
            # √çndices das classes mais frequentes
            top_class_indices = unique[np.argsort(counts)[-max_classes:]] 
            
            mask = np.isin(labels, top_class_indices)
            labels_filtered = labels[mask]
            preds_filtered = preds[mask]
            class_names_filtered = [class_names[i] for i in top_class_indices]
            
            # Mapeia os √≠ndices filtrados para 0..N para o plot
            old_to_new_index = {old: new for new, old in enumerate(top_class_indices)}
            labels_filtered = np.array([old_to_new_index[y] for y in labels_filtered])
            # Predi√ß√µes que n√£o est√£o no top N s√£o mapeadas para -1 e removidas.
            preds_filtered = np.array([old_to_new_index.get(y, -1) for y in preds_filtered]) 
            
            # Remove predi√ß√µes que n√£o est√£o no set de classes filtradas
            valid_preds_mask = (preds_filtered >= 0)
            labels_filtered = labels_filtered[valid_preds_mask]
            preds_filtered = preds_filtered[valid_preds_mask]

            cm = confusion_matrix(labels_filtered, preds_filtered, normalize='true')
            class_names = class_names_filtered
        else:
            cm = confusion_matrix(labels, preds, normalize='true')
        
        plt.figure(figsize=(12, 10))
        plt.imshow(cm, cmap='viridis', aspect='auto')
        plt.title("Zero-Shot Confusion Matrix", fontsize=14)
        plt.colorbar()
        
        # Ajusta o tamanho da fonte
        fontsize = max(6, 12 - len(class_names) // 10)
        
        plt.xticks(np.arange(len(class_names)), class_names, rotation=90, fontsize=fontsize)
        plt.yticks(np.arange(len(class_names)), class_names, fontsize=fontsize)
        plt.xlabel('Predicted', fontsize=10)
        plt.ylabel('True', fontsize=10)
        plt.tight_layout()
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f" ¬†‚úÖ Matriz de confus√£o salva: {output_path}")
    except Exception as e:
        print(f" ¬†‚ö†Ô∏è ¬†Erro ao gerar matriz de confus√£o: {e}")
        traceback.print_exc()


# ============================
# AVALIA√á√ÉO PRINCIPAL
# ============================

def main():
    print(f"üöÄ Iniciando avalia√ß√£o Zero-Shot CLIP")
    print(f"üì¶ Modelo: {MODEL_NAME}")
    print(f"üíª Device: {DEVICE}")
    print(f"üìä Datasets encontrados: {len(DATASETS)}\n")
    
    if not DATASETS:
        print("‚ùå Nenhum dataset encontrado! Verifique o arquivo summary.json")
        return
    
    print("üîß Carregando modelo CLIP...")
    # Garante que o modelo e o processor s√£o carregados apenas uma vez
    model = AutoModel.from_pretrained(MODEL_NAME).to(DEVICE)
    processor = AutoProcessor.from_pretrained(MODEL_NAME)
    model.eval()
    print("‚úÖ Modelo carregado!\n")

    summary = {
        "model": MODEL_NAME,
        "device": DEVICE,
        "total_datasets": len(DATASETS),
        "successful": 0,
        "failed": 0,
        "results": {}
    }

    for dataset_name, dataset_path in DATASETS.items():
        print(f"\n{'='*60}")
        print(f"üìä Avaliando dataset: {dataset_name}")
        print(f"{'='*60}")
        
        try:
            template = load_templates(dataset_name)
            if not template:
                print(f"‚ö†Ô∏è ¬†Sem template, usando templates gen√©ricos")
            
            result = load_embeddings_and_generate_text(
                dataset_name, dataset_path, template, model, processor
            )
            
            if result[0] is None:
                print(f"‚è≠Ô∏è ¬†Pulando {dataset_name}")
                summary["failed"] += 1
                continue
                
            image_embeds, text_embeds, labels, class_names = result

            acc, preds = evaluate_zero_shot(image_embeds.cpu(), text_embeds.cpu(), labels)
            print(f"\n‚úÖ Acur√°cia zero-shot: {acc:.4f}")

            plot_path = os.path.join(RESULTS_DIR, f"{dataset_name}_cm.png")
            plot_confusion_matrix(labels, preds, class_names, plot_path)

            summary["successful"] += 1
            summary["results"][dataset_name] = {
                "accuracy": float(acc),
                "num_classes": len(class_names),
                "num_images": len(labels),
                "confusion_matrix_plot": plot_path
            }
            
        except Exception as e:
            print(f"‚ùå Erro ao processar {dataset_name}: {e}")
            traceback.print_exc()
            summary["failed"] += 1
            continue

    # Salva resultados
    out_path = os.path.join(RESULTS_DIR, "zero_shot_results.json")
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(summary, f, indent=4, ensure_ascii=False)
    
    summary_path = os.path.join(RESULTS_DIR, "accuracy_summary.json")
    accuracy_only = {name: f"{data['accuracy']:.4f}" 
                      for name, data in summary["results"].items()}
    
    with open(summary_path, "w", encoding="utf-8") as f:
        json.dump(accuracy_only, f, indent=4, ensure_ascii=False)
    
    print(f"\n{'='*60}")
    print(f"üìä RESUMO FINAL")
    print(f"{'='*60}")
    print(f"‚úÖ Datasets processados com sucesso: {summary['successful']}")
    print(f"‚ùå Datasets com falha: {summary['failed']}")
    
    if summary["results"]:
        print(f"\nüìà Acur√°cias (ordenadas):")
        for name, data in sorted(summary["results"].items(), 
                                 key=lambda x: x[1]["accuracy"], 
                                 reverse=True):
            print(f" ¬†{name:30s}: {data['accuracy']:.4f} "
                  f"({data['num_classes']} classes, {data['num_images']} imgs)")
    
    print(f"\nüìÅ Resultados salvos em:")
    print(f" ¬†- {out_path}")
    print(f" ¬†- {summary_path}")
    print(f" ¬†- Matrizes de confus√£o: {RESULTS_DIR}/")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    main()